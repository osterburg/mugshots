{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__ is not \"2.0.0-beta1\":\n",
    "    !pip install tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import h5py\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    hdf5_path = 'data/dataset.hdf5'\n",
    "    hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "    \n",
    "    X_train = hdf5_file['train_inpt'][:]\n",
    "    y_train = hdf5_file['train_real'][:]\n",
    "    X_test = hdf5_file['test_inpt'][:]\n",
    "    y_test = hdf5_file['test_real'][:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_source_images, train_target_images, test_source_images, test_target_images = load_dataset()\n",
    "\n",
    "train_source_images = train_source_images.reshape(train_source_images.shape[0], 256, 256, 3).astype('float32')\n",
    "train_source_images = train_source_images / 255.\n",
    "train_target_images = train_target_images.reshape(train_target_images.shape[0], 256, 256, 3).astype('float32')\n",
    "train_target_images = train_target_images / 255.\n",
    "test_source_images = test_source_images.reshape(test_source_images.shape[0], 256, 256, 3).astype('float32')\n",
    "test_source_images = test_source_images / 255.\n",
    "test_target_images = test_target_images.reshape(test_target_images.shape[0], 256, 256, 3).astype('float32')\n",
    "test_target_images = test_target_images / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset sizes\n",
    "print(train_source_images.shape)\n",
    "print(train_target_images.shape)\n",
    "print(test_source_images.shape)\n",
    "print(test_target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400  # train_source_images.shape[0] # number of training images\n",
    "BATCH_SIZE = 4 # training batch size (memory dependent)\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data. I've eliminated shuffling here.\n",
    "train_source_dataset = tf.data.Dataset.from_tensor_slices(train_source_images).batch(BATCH_SIZE)\n",
    "train_target_dataset = tf.data.Dataset.from_tensor_slices(train_target_images).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "The Image-to-Image paper notes that it uses the U-Net as the generator. \n",
    "\n",
    "![U-Net](u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(input_shape):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Encoder network\n",
    "    x = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv0')(x)\n",
    "    conv0 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv1')(conv0)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv1 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv2')(conv1)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv2 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv3')(conv2)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv3 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv4')(conv3)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv5')(conv4)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv5 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv6')(conv5)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv6 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv7')(conv6)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv7 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Fully-connected layers to allow parts to move around.\n",
    "    # If you are running out of memory, you can comment some of them out.\n",
    "\n",
    "    # Flatten -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Reshape\n",
    "    x = tf.keras.layers.Flatten()(conv7)\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense1')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense2')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense3')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense4')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense5')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Reshape((1, 1, 512))(x)\n",
    "\n",
    "    # Decoder network\n",
    "    # tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv7')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat6')([conv6, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv6')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat5')([conv5, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv5')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat4')([conv4, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv4')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat3')([conv3, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat2')([conv2, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat1')([conv1, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> TanH\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat0')([conv0, x])\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same',\n",
    "                                              kernel_initializer=initializer,\n",
    "                                              use_bias=False, activation='tanh', \n",
    "                                              name='dec_conv0')(x)\n",
    "\n",
    "    # Return model. \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator((256, 256, 3))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator takes the input shape of the image file and in our case it's (256, 256, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(source_shape, target_shape):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    input_image = tf.keras.Input(source_shape, name='input_image')\n",
    "    target_image = tf.keras.Input(target_shape, name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat')([input_image, target_image])\n",
    "\n",
    "    # Conv -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv0')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), name='disc_conv3', \n",
    "                               kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> Sigmoid\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    outputs = tf.keras.layers.Conv2D(1, (4, 4), strides=(1, 1), name='validity', use_bias=False,\n",
    "                                     kernel_initializer=initializer, activation='sigmoid')(x)\n",
    "\n",
    "    # Return model\n",
    "    return tf.keras.Model(inputs=[input_image, target_image], outputs=outputs, name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator((256, 256, 3),(256,256,3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss functions for Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_weight and gan_weight are taken from the Image-to-Iamge paper.\n",
    "# The numbers scale the two components of the loss function in the GAN.\n",
    "l1_weight = 100.0\n",
    "gan_weight = 1.0\n",
    "\n",
    "# Epsilon\n",
    "epsilon = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output): \n",
    "    total_loss = tf.reduce_mean(-(tf.math.log(real_output + epsilon) + tf.math.log(1 - fake_output + epsilon)))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, target_images, generated_images):\n",
    "    gen_loss_GAN = tf.reduce_mean(-tf.math.log(fake_output + epsilon))\n",
    "    gen_loss_L1 = tf.reduce_mean(tf.math.abs(target_images - generated_images))\n",
    "    total_loss = gen_loss_GAN * gan_weight + gen_loss_L1 * l1_weight\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.99, epsilon=epsilon)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.99, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'data/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The use of `tf.function` causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(source_images, target_images, epoch_num):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(source_images, training=True)\n",
    "\n",
    "        real_output = discriminator((source_images, target_images), training=True)\n",
    "        fake_output = discriminator((source_images, generated_images), training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output, target_images, generated_images)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        report_gen_loss = tf.math.reduce_sum(gen_loss)\n",
    "        report_disc_loss = tf.math.reduce_sum(disc_loss)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return report_gen_loss, report_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(source_dataset, target_dataset, epochs):\n",
    "    epoch_start = 0\n",
    "\n",
    "    # Set up history reporting\n",
    "    history = {}\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        #source_iterator = source_dataset.make_one_shot_iterator()\n",
    "        source_index = 0\n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "\n",
    "        for image_target_batch in target_dataset:\n",
    "            image_source_batch = train_source_images[np.array(list(range(source_index, source_index + BATCH_SIZE)))]\n",
    "            report_gen_loss, report_disc_loss = train_step(image_source_batch, image_target_batch, epoch)\n",
    "            source_index = source_index + BATCH_SIZE\n",
    "            total_gen_loss = total_gen_loss + report_gen_loss\n",
    "            total_disc_loss = total_disc_loss + report_disc_loss\n",
    "\n",
    "        # Record and print the losses\n",
    "        total_gen_loss_adj = (total_gen_loss / BUFFER_SIZE) / l1_weight\n",
    "        total_disc_loss_adj = total_disc_loss / BUFFER_SIZE\n",
    "        gen_loss_list.append(total_gen_loss_adj)\n",
    "        disc_loss_list.append(total_disc_loss_adj)\n",
    "        \n",
    "        print(\"Generator Loss {}\".format(total_gen_loss_adj))\n",
    "        print(\"Discriminator Loss {}\".format(total_disc_loss_adj))\n",
    "        \n",
    "        history['gen_loss'] = gen_loss_list\n",
    "        history['disc_loss'] = disc_loss_list\n",
    "\n",
    "        # Save images every 5 epochs.\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generated_image = generator(test_source_images[np.array([0])], training=False)\n",
    "            prediction = np.reshape(generated_image, (256, 256, 3))\n",
    "            final_image = np.clip((prediction * 255), 0, 255).astype(np.uint8)\n",
    "            generated_image2 = Image.fromarray(final_image)\n",
    "            generated_image2.save('data/sample_output1_{:04d}.jpg'.format(epoch + 1))\n",
    "\n",
    "            generated_image = generator(test_source_images[np.array([1])], training=False)\n",
    "            prediction = np.reshape(generated_image, (256, 256, 3))\n",
    "            final_image = np.clip((prediction * 255), 0, 255).astype(np.uint8)\n",
    "            generated_image2 = Image.fromarray(final_image)\n",
    "            generated_image2.save('data/sample_output2_{:04d}.jpg'.format(epoch + 1))\n",
    "\n",
    "            generated_image = generator(test_source_images[np.array([2])], training=False)\n",
    "            prediction = np.reshape(generated_image, (256, 256, 3))\n",
    "            final_image = np.clip((prediction * 255), 0, 255).astype(np.uint8)\n",
    "            generated_image2 = Image.fromarray(final_image)\n",
    "            generated_image2.save('data/sample_output3_{:04d}.jpg'.format(epoch + 1))\n",
    "\n",
    "            generated_image = generator(test_source_images[np.array([3])], training=False)\n",
    "            prediction = np.reshape(generated_image, (256, 256, 3))\n",
    "            final_image = np.clip((prediction * 255), 0, 255).astype(np.uint8)\n",
    "            generated_image2 = Image.fromarray(final_image)\n",
    "            generated_image2.save('data/sample_output4_{:04d}.jpg'.format(epoch + 1))\n",
    "\n",
    "        # Save the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        # Print time every 1 epochs\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print ('Time for epoch {} is {} seconds\\n'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(train_source_dataset, train_target_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "    \n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    generated_image = generator(test_source_images[np.array([i])], training=False)\n",
    "    prediction = np.reshape(generated_image, (256, 256, 3))\n",
    "    final_image = np.clip((prediction * 255), 0, 255).astype(np.uint8)\n",
    "    generated_image = Image.fromarray(final_image)\n",
    "    generated_image.save('dataset/final.{:04d}.jpg'.format(i + 1))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    # the training=True is intentional here since\n",
    "    # we want the batch statistics while running the model\n",
    "    # on the test dataset. If we use training=False, we will get\n",
    "    # the accumulated statistics learned from the training dataset\n",
    "    # (which we don't want)\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp, tar in test_dataset.take(5):\n",
    "    generate_images(generator, inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
